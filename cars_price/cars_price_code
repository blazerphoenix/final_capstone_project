# Import required libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt 
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# Load the dataset into a Pandas DataFrame
cars_price = pd.read_csv("C:/Users/dhana/Downloads/cars_price.csv")

# Handle missing values by replacing '?' with NaN and dropping rows with NaN
cars_price.replace('?', np.nan, inplace=True)
cars_price.dropna(inplace=True)

# Convert selected columns to appropriate data types
columns_to_convert = ['normalized-losses', 'bore', 'stroke', 'horsepower', 'peak-rpm', 'price']
cars_price[columns_to_convert] = cars_price[columns_to_convert].astype(float)

# Perform one-hot encoding for categorical variables
cars_price_encoded = pd.get_dummies(cars_price)
cars_price_encoded = cars_price_encoded.astype(int)

# Separate features (X) and target variable (y)
X = cars_price_encoded.drop('price', axis=1)
y = cars_price_encoded['price']

# Split the data into train and test sets
x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize the feature values using StandardScaler
scaler = StandardScaler()
x_train_scaled = scaler.fit_transform(x_train)
x_test_scaled = scaler.transform(x_test)

# Initialize a Random Forest Regressor model
rf_model = RandomForestRegressor(random_state=42)

# Train the model on the scaled training data
rf_model.fit(x_train_scaled, y_train)

# Make predictions on the test set
y_pred = rf_model.predict(x_test_scaled)

# Evaluate the model performance using regression metrics
mse = mean_squared_error(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

# Print regression metrics
print("Mean Squared Error:", mse)
print("Mean Absolute Error:", mae)
print("R-squared:", r2)

# Extract feature importance scores and create a DataFrame
feature_importance = pd.DataFrame({'Feature': X.columns, 'Importance': rf_model.feature_importances_})
feature_importance = feature_importance.sort_values(by='Importance', ascending=False)

# Visualize feature importance using a bar plot
plt.figure(figsize=(5, 15))
sns.barplot(x='Importance', y='Feature', data=feature_importance)
plt.title('Feature Importance')
plt.show()
print("Mean Absolute Error:", mae)
print("R-squared:", r2)
