# Import required libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, f1_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# Load the dataset into a Pandas DataFrame
cars_class = pd.read_csv("cars_class (1).csv")

# Separate features (X) and target variable (y)
X = cars_class.drop('Class', axis=1)
y = cars_class['Class']

# Split the data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize the feature values using StandardScaler
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Initialize a Random Forest Classifier
model = RandomForestClassifier(random_state=42)

# Train the model on the scaled training data
model.fit(X_train, y_train)

# Save the final trained model
final_model = model

# Make predictions on the test set
y_pred = final_model.predict(X_test)

# Evaluate the model performance
accuracy = accuracy_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred, average='weighted')
conf_matrix = confusion_matrix(y_test, y_pred)

# Print evaluation metrics
print("Accuracy: ", accuracy)
print("F1 Score: ", f1)
print("Confusion Matrix:", conf_matrix)

# Extract feature importance scores and create a DataFrame
feature_importance = pd.DataFrame({'Feature': X.columns, 'Importance': model.feature_importances_})
feature_importance = feature_importance.sort_values(by='Importance', ascending=False)

# Visualize feature importance using a bar plot
plt.figure(figsize=(10, 6))
sns.barplot(x='Importance', y='Feature', data=feature_importance)
plt.title('Feature Importance')
plt.show()
